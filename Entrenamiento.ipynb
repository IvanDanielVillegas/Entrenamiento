{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CARGAR DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraer archivos de datos .ZIP\n",
    "import zipfile as zf\n",
    "\n",
    "ArchivoZIP = \"Tesis/Datos/Paciente_ID_cristian.zip\"\n",
    "ArchivoDES = 'Tesis/Datos/'\n",
    "files = zf.ZipFile(ArchivoZIP, 'r')\n",
    "files.extractall(ArchivoDES)\n",
    "files.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm {ArchivoZIP}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paciente_ID_001  Paciente_ID_004  Paciente_ID_007  Paciente_ID_777\n",
      "Paciente_ID_002  Paciente_ID_005  Paciente_ID_008  Paciente_ID_cristian\n",
      "Paciente_ID_003  Paciente_ID_006  Paciente_ID_009\n"
     ]
    }
   ],
   "source": [
    "!ls 'Tesis/Datos/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/nrdaza/work/home/Tesis/Datos/Paciente_ID_001/',\n",
       " '/home/nrdaza/work/home/Tesis/Datos/Paciente_ID_002/',\n",
       " '/home/nrdaza/work/home/Tesis/Datos/Paciente_ID_003/',\n",
       " '/home/nrdaza/work/home/Tesis/Datos/Paciente_ID_004/',\n",
       " '/home/nrdaza/work/home/Tesis/Datos/Paciente_ID_005/',\n",
       " '/home/nrdaza/work/home/Tesis/Datos/Paciente_ID_006/',\n",
       " '/home/nrdaza/work/home/Tesis/Datos/Paciente_ID_007/',\n",
       " '/home/nrdaza/work/home/Tesis/Datos/Paciente_ID_008/',\n",
       " '/home/nrdaza/work/home/Tesis/Datos/Paciente_ID_009/',\n",
       " '/home/nrdaza/work/home/Tesis/Datos/Paciente_ID_777/',\n",
       " '/home/nrdaza/work/home/Tesis/Datos/Paciente_ID_cristian/']"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "my_dirs2 = glob(\"/home/nrdaza/work/home/Tesis/Datos/*/\")\n",
    "my_dirs2.sort()\n",
    "my_dirs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OZ, OD, Cejas, Mandibula, nada \n",
    "dict_gestos = ['Gesto_1','Gesto_2','Gesto_3','Gesto_4','Gesto_5'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datos_1.csv',\n",
       " 'datos_2.csv',\n",
       " 'datos_3.csv',\n",
       " 'datos_4.csv',\n",
       " 'datos_5.csv',\n",
       " 'datos_6.csv',\n",
       " 'datos_7.csv',\n",
       " 'datos_8.csv',\n",
       " 'datos_9.csv',\n",
       " 'datos_10.csv',\n",
       " 'datos_11.csv',\n",
       " 'datos_12.csv',\n",
       " 'datos_13.csv',\n",
       " 'datos_14.csv',\n",
       " 'datos_15.csv',\n",
       " 'datos_16.csv',\n",
       " 'datos_17.csv',\n",
       " 'datos_18.csv',\n",
       " 'datos_19.csv',\n",
       " 'datos_20.csv',\n",
       " 'datos_21.csv',\n",
       " 'datos_22.csv',\n",
       " 'datos_23.csv',\n",
       " 'datos_24.csv',\n",
       " 'datos_25.csv',\n",
       " 'datos_26.csv',\n",
       " 'datos_27.csv',\n",
       " 'datos_28.csv',\n",
       " 'datos_29.csv',\n",
       " 'datos_30.csv']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dict_datos = ['datos_1.csv','datos_2.csv','datos_3.csv','datos_4.csv','datos_5.csv','datos_6.csv', 'datos_7.csv', 'datos_8.csv', 'datos_9.csv', 'datos_10.csv']\n",
    "dict_datos = glob(\"/home/nrdaza/work/home/Tesis/Datos/Paciente_ID_777/Gesto_1/Datos_CSV_ULTRACORTEX/*\")\n",
    "dict_datos.sort()\n",
    "dict_datos\n",
    "datos = []\n",
    "for i in range(len(dict_datos)):\n",
    "    datos.append(f'datos_{i+1}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Verificar_datos(my_dirs2, dict_gestos, datos):\n",
    "    shapes=[]\n",
    "#     for i in range(len(my_dirs2)):\n",
    "    for j in range(len(dict_gestos)):\n",
    "            #print(my_dirs2[i]+dict_gestos[j])\n",
    "            for k in range(len(datos)):\n",
    "              #print(my_dirs2[i]+dict_gestos[j]+'/Datos_CSV_MYO/'+dict_datos[k])\n",
    "              df = pd.read_csv(my_dirs2[10]+dict_gestos[j]+'/Datos_CSV_ULTRACORTEX/'+datos[k],encoding='ISO-8859-1', skiprows = 2,sep=';')\n",
    "              shapes.append(df.shape)\n",
    "              #print(i,j,df.shape)\n",
    "    print(np.unique(shapes), len(shapes))\n",
    "    \n",
    "    from collections import Counter\n",
    "    counter=Counter(shapes)\n",
    "    print(counter)\n",
    "#     i = 9\n",
    "#     j = 4\n",
    "#     shapess = []\n",
    "#     for k in range(len(datos)):\n",
    "#         df = pd.read_csv(my_dirs2[i]+dict_gestos[j]+'/Datos_CSV_ULTRACORTEX/'+datos[k],encoding='ISO-8859-1', skiprows = 2,sep=';')\n",
    "#         shapess.append(df.shape)\n",
    "#         np.unique(shapess), len(shapess)\n",
    "#         from collections import Counter\n",
    "#         counter=Counter(shapess)\n",
    "#         print(counter)\n",
    "#         print(my_dirs2[i]+dict_gestos[j]+'/Datos_CSV_ULTRACORTEX/'+datos[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 17 622 625] 100\n",
      "Counter({(625, 17): 90, (622, 17): 10})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Verificar_datos(my_dirs2, dict_gestos, datos[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 150 (625, 16)\n",
      "2 150 (625, 16)\n",
      "3 150 (625, 16)\n",
      "4 150 (625, 16)\n",
      "5 150 (625, 16)\n",
      "6 150 (625, 16)\n",
      "7 150 (625, 16)\n",
      "8 150 (625, 16)\n",
      "9 150 (625, 16)\n",
      "10 150 (625, 16)\n",
      "11 150 (625, 16)\n",
      "12 150 (625, 16)\n",
      "13 150 (625, 16)\n",
      "14 150 (625, 16)\n",
      "15 150 (625, 16)\n",
      "16 150 (625, 16)\n",
      "17 150 (625, 16)\n",
      "18 150 (625, 16)\n",
      "19 150 (625, 16)\n",
      "20 150 (625, 16)\n",
      "21 150 (625, 16)\n",
      "22 150 (625, 16)\n",
      "23 150 (625, 16)\n",
      "24 150 (625, 16)\n",
      "25 150 (625, 16)\n",
      "26 150 (625, 16)\n",
      "27 150 (625, 16)\n",
      "28 150 (625, 16)\n",
      "29 150 (625, 16)\n",
      "30 150 (625, 16)\n",
      "31 150 (625, 16)\n",
      "32 150 (625, 16)\n",
      "33 150 (625, 16)\n",
      "34 150 (625, 16)\n",
      "35 150 (625, 16)\n",
      "36 150 (625, 16)\n",
      "37 150 (625, 16)\n",
      "38 150 (625, 16)\n",
      "39 150 (625, 16)\n",
      "40 150 (625, 16)\n",
      "41 150 (625, 16)\n",
      "42 150 (625, 16)\n",
      "43 150 (625, 16)\n",
      "44 150 (625, 16)\n",
      "45 150 (625, 16)\n",
      "46 150 (625, 16)\n",
      "47 150 (625, 16)\n",
      "48 150 (625, 16)\n",
      "49 150 (625, 16)\n",
      "50 150 (625, 16)\n",
      "51 150 (625, 16)\n",
      "52 150 (625, 16)\n",
      "53 150 (625, 16)\n",
      "54 150 (625, 16)\n",
      "55 150 (625, 16)\n",
      "56 150 (625, 16)\n",
      "57 150 (625, 16)\n",
      "58 150 (625, 16)\n",
      "59 150 (625, 16)\n",
      "60 150 (625, 16)\n",
      "61 150 (625, 16)\n",
      "62 150 (625, 16)\n",
      "63 150 (625, 16)\n",
      "64 150 (625, 16)\n",
      "65 150 (625, 16)\n",
      "66 150 (625, 16)\n",
      "67 150 (625, 16)\n",
      "68 150 (625, 16)\n",
      "69 150 (625, 16)\n",
      "70 150 (625, 16)\n",
      "71 150 (625, 16)\n",
      "72 150 (625, 16)\n",
      "73 150 (625, 16)\n",
      "74 150 (625, 16)\n",
      "75 150 (625, 16)\n",
      "76 150 (625, 16)\n",
      "77 150 (625, 16)\n",
      "78 150 (625, 16)\n",
      "79 150 (625, 16)\n",
      "80 150 (625, 16)\n",
      "81 150 (625, 16)\n",
      "82 150 (625, 16)\n",
      "83 150 (625, 16)\n",
      "84 150 (625, 16)\n",
      "85 150 (625, 16)\n",
      "86 150 (625, 16)\n",
      "87 150 (625, 16)\n",
      "88 150 (625, 16)\n",
      "89 150 (625, 16)\n",
      "90 150 (625, 16)\n",
      "91 150 (625, 16)\n",
      "92 150 (625, 16)\n",
      "93 150 (625, 16)\n",
      "94 150 (625, 16)\n",
      "95 150 (625, 16)\n",
      "96 150 (625, 16)\n",
      "97 150 (625, 16)\n",
      "98 150 (625, 16)\n",
      "99 150 (625, 16)\n",
      "100 150 (625, 16)\n",
      "101 150 (625, 16)\n",
      "102 150 (625, 16)\n",
      "103 150 (625, 16)\n",
      "104 150 (625, 16)\n",
      "105 150 (625, 16)\n",
      "106 150 (625, 16)\n",
      "107 150 (625, 16)\n",
      "108 150 (625, 16)\n",
      "109 150 (625, 16)\n",
      "110 150 (625, 16)\n",
      "111 150 (625, 16)\n",
      "112 150 (625, 16)\n",
      "113 150 (625, 16)\n",
      "114 150 (625, 16)\n",
      "115 150 (625, 16)\n",
      "116 150 (625, 16)\n",
      "117 150 (625, 16)\n",
      "118 150 (625, 16)\n",
      "119 150 (625, 16)\n",
      "120 150 (625, 16)\n",
      "121 150 (625, 16)\n",
      "122 150 (625, 16)\n",
      "123 150 (625, 16)\n",
      "124 150 (625, 16)\n",
      "125 150 (625, 16)\n",
      "126 150 (625, 16)\n",
      "127 150 (625, 16)\n",
      "128 150 (625, 16)\n",
      "129 150 (625, 16)\n",
      "130 150 (625, 16)\n",
      "131 150 (625, 16)\n",
      "132 150 (625, 16)\n",
      "133 150 (625, 16)\n",
      "134 150 (625, 16)\n",
      "135 150 (625, 16)\n",
      "136 150 (625, 16)\n",
      "137 150 (625, 16)\n",
      "138 150 (625, 16)\n",
      "139 150 (625, 16)\n",
      "140 150 (625, 16)\n",
      "141 150 (625, 16)\n",
      "142 150 (625, 16)\n",
      "143 150 (625, 16)\n",
      "144 150 (625, 16)\n",
      "145 150 (625, 16)\n",
      "146 150 (625, 16)\n",
      "147 150 (625, 16)\n",
      "148 150 (625, 16)\n",
      "149 150 (625, 16)\n",
      "150 150 (625, 16)\n"
     ]
    }
   ],
   "source": [
    "features=[]\n",
    "# for i in range(len(my_dirs2)):\n",
    "for j in range(len(dict_gestos)):\n",
    "    #print(my_dirs2[i]+dict_gestos[j])\n",
    "    for k in range(len(datos)):\n",
    "      #print(my_dirs2[i]+dict_gestos[j]+'/Datos_CSV_MYO/'+dict_datos[k])\n",
    "      df = pd.read_csv(my_dirs2[9]+dict_gestos[j]+'/Datos_CSV_ULTRACORTEX/'+datos[k],encoding='ISO-8859-1', skiprows = 2,sep=';')\n",
    "      if (df.shape[0] != 625):\n",
    "            tamaño = df.shape[0]\n",
    "            for i in range(625-df.shape[0]):\n",
    "                df.loc[df.shape[0]+i+1] = df.values[tamaño-1-i]\n",
    "      features.append(df.iloc[0:625,0:16].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(150):    \n",
    "    len(features), features[i].shape\n",
    "    if (features[i].shape == (625,16)):\n",
    "        print(i+1,len(features), features[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, (625, 16))"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features), features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 625, 16)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_array = np.array(features)\n",
    "features_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_array[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VECTOR DE ETIQUETAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
       "       4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Haciendo nuestro vector de etiquetas\n",
    "long = len(dict_datos)\n",
    "labels = np.concatenate((np.zeros(long),np.ones(long),np.ones(long)*2,np.ones(long)*3,np.ones(long)*4),axis=0)\n",
    "labels\n",
    "\n",
    "def repeat(arr, count):\n",
    "    return np.stack([arr for _ in range(count)], axis=0)\n",
    "\n",
    "# labels = repeat(labels,len(my_dirs2)) # Cantidad de pacientes\n",
    "labels = repeat(labels,1)\n",
    "\n",
    "labels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "        3., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
       "        4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.]),\n",
       " (150,))"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.reshape(labels,150)\n",
    "labels, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AJUSTE DE TENSOR DE ENTRADA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 625, 16), -16253.944912877403)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_array.shape, np.sum(features_array[0:150,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 10000), -16253.944912877403)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_array2 = np.reshape(features_array,(150,10000))\n",
    "features_array2.shape, np.sum(features_array2[0:150,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xsplit = int(features_array2.shape[0] * 0.8) \n",
    "X_train_split = features_array2[0:Xsplit,:]\n",
    "X_test_split = features_array2[Xsplit:,:]\n",
    "labels_train = labels[0:Xsplit]\n",
    "labels_test = labels[Xsplit:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution: [0. 1. 2. 3.], total classes 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Label distribution: {}, total classes {}\".format(np.unique(labels_train), len(np.unique(labels_train))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
